user is allocated to a person
user can authenticate to aws 
using policies we can authorize services in aws(like list, create the buckets, you can relate)
user>policies(permissions)

Roles are attached to the service to access the service 


EC2 instance-types
general purpose
memory optimized
compute optimized
storage optimized
accelerated computing
hpc optimized

latency - request that travels from one place to another place to get some information from application (b/w servers)

ec2 instance has the public key and we have private key with us(sudhamsh-dev.pem)

VPC
NACL - Applied at a subnet level(additional layer of security on top of sg)(Deny and Allow Rules)(first layer of defence for a subnet)
sg - Applied at a instance level(Allow Rules)
within a subnet, if we wanna assign same security group to multiple servers, automation for sg, instead of assigning same thing again and again, we can define as part of nacl
NAT gateway - masks the ipaddress when when travelling via route table, nat gateway sits in the public subnet

A user from external world wanna access a resource in a VPC
user>igw>public-subnet(load-balancer)>Route-tables>security-group>nacl

Bastion Host - 
the servers sitting in the private subnet won't be having the public-ipaddress, we can't ssh into these servers directly, to access these private servers we create bastion Host in public subnet, with bastion-host we can ssh into the servers sitting in the private subnets
it's the mediator b/w the server sitting in private subnet and user sitting in public subnet
bastion-host should be in the same vpc where the private subnet is residing in

container basically a package contains the application code, software and dependencies to run the application


secrets mangement on aws:
systems manager(within the system-manager we've a parameter store(we can store the sensitive information like dockerhub-username and password)aws resources retrives the secrets from parameter-store using iam Roles)
secrets manager(very-sensitive) for storing DB secrets and API Tokens(it rotates the secrets once in desired days that we configure(90, 30, 2 days))

secerets manger with the parameter store would be a great and cost-effective option

AWS Config(track resource inventory and changes(helps us know what are complaint and non-complaint)) - we can create a rule and integrate it with lambda function
Examples(these are complaince for specific projects)  - ec2 monitoring enabled must be mandatory, all the s3 buckets that we're creating should have lifecycle mangement rules, tags must be mandatory for the ec2 instances

periodic(Runs on the frequency that we choose)


LAMBDA(serverless compute)(it is automatically created and automatically tear down) - cloud cost optimization, security/complaince
we can trigger lambda functions with wide range of services(s3) and perform activities which are basically event driven actions
when should we use the ec2 and lambda functions
let's say if my organization is using 20 aws resources, we can write the lambda functions to  govern(basically a combo of(monitor and report) )resource usage
we can also tell the cloudwatch by configuring the cron-job to trigger the lambda function
lambda function is event driven, it has to be invoked, lambda can't run by itself(basically event could be a cloudwatch event, basically we can tell cloudwatch to trigger at a specfic time)
when we enable the ENABLE FUNCTION(Use function URLs to assign HTTP(S) endpoints to your Lambda function) radio button in the lambda UI, we get a public IP address for the application that we written in lambda
if we wanna trigger the lambda function manually we can use the test button, if lambda wanna get invoked by a service we need to ensure trigger is got enabled by a specific service

default execution time for lambda is 3 seconds and max is 15 minutes
we need to write the steps that we wanna perform in plain english then refer the boto3 documentation
